{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b75c3aad",
   "metadata": {},
   "source": [
    "### Agentic ai \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e935099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv \n",
    "from rich import print\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34d2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm= ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c7e22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The Groq platform is a relatively new and innovative technology stack that focuses on accelerating machine learning\n",
       "<span style=\"font-weight: bold\">(</span>ML<span style=\"font-weight: bold\">)</span> and artificial intelligence <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span> workloads. Here's an overview:\n",
       "\n",
       "**What is Groq?**\n",
       "Groq is a software-defined, hardware-accelerated platform that enables fast and efficient processing of machine \n",
       "learning and AI workloads. The platform is designed to simplify the development, deployment, and management of \n",
       "ML/AI models, making it easier for organizations to adopt and scale their AI capabilities.\n",
       "\n",
       "**Key Features:**\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Hardware Acceleration**: Groq's platform is built on top of custom-designed ASICs <span style=\"font-weight: bold\">(</span>Application-Specific \n",
       "Integrated Circuits<span style=\"font-weight: bold\">)</span> that are optimized for ML/AI workloads. This hardware acceleration provides a significant \n",
       "boost in performance and efficiency compared to traditional CPUs and GPUs.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Software-Defined**: The Groq platform is software-defined, meaning that it provides a flexible and \n",
       "programmable interface for developers to create, deploy, and manage ML/AI models. This allows for greater \n",
       "customization and control over the platform.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Tensor Processing**: Groq's platform is designed to efficiently process tensor operations, which are a \n",
       "fundamental component of many ML/AI algorithms. This enables fast and accurate processing of complex models.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Scalability**: The Groq platform is designed to scale horizontally, allowing organizations to easily add or \n",
       "remove nodes as needed to accommodate changing workloads.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Integration with Popular Frameworks**: Groq supports popular ML/AI frameworks such as TensorFlow, PyTorch, and\n",
       "Caffe, making it easy for developers to integrate the platform into their existing workflows.\n",
       "\n",
       "**Benefits:**\n",
       "The Groq platform offers several benefits, including:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Faster Processing Times**: Groq's hardware acceleration and optimized software stack enable faster processing \n",
       "times for ML/AI workloads, reducing the time it takes to train and deploy models.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Improved Efficiency**: The platform's efficient design and optimized hardware reduce power consumption and \n",
       "heat generation, making it more cost-effective and environmentally friendly.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Simplified Development**: Groq's software-defined platform and support for popular frameworks simplify the \n",
       "development and deployment of ML/AI models, reducing the complexity and expertise required.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Increased Accuracy**: The platform's optimized hardware and software enable more accurate processing of ML/AI \n",
       "models, leading to better outcomes and decision-making.\n",
       "\n",
       "**Target Use Cases:**\n",
       "The Groq platform is designed for a wide range of use cases, including:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Computer Vision**: Image and video processing, object detection, and image classification.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Natural Language Processing**: Text classification, sentiment analysis, and language translation.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Recommendation Systems**: Personalized recommendations, predictive analytics, and decision-making.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Autonomous Vehicles**: Sensor processing, object detection, and motion forecasting.\n",
       "\n",
       "Overall, the Groq platform has the potential to revolutionize the way organizations approach machine learning and \n",
       "artificial intelligence, enabling faster, more efficient, and more accurate processing of complex workloads.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The Groq platform is a relatively new and innovative technology stack that focuses on accelerating machine learning\n",
       "\u001b[1m(\u001b[0mML\u001b[1m)\u001b[0m and artificial intelligence \u001b[1m(\u001b[0mAI\u001b[1m)\u001b[0m workloads. Here's an overview:\n",
       "\n",
       "**What is Groq?**\n",
       "Groq is a software-defined, hardware-accelerated platform that enables fast and efficient processing of machine \n",
       "learning and AI workloads. The platform is designed to simplify the development, deployment, and management of \n",
       "ML/AI models, making it easier for organizations to adopt and scale their AI capabilities.\n",
       "\n",
       "**Key Features:**\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Hardware Acceleration**: Groq's platform is built on top of custom-designed ASICs \u001b[1m(\u001b[0mApplication-Specific \n",
       "Integrated Circuits\u001b[1m)\u001b[0m that are optimized for ML/AI workloads. This hardware acceleration provides a significant \n",
       "boost in performance and efficiency compared to traditional CPUs and GPUs.\n",
       "\u001b[1;36m2\u001b[0m. **Software-Defined**: The Groq platform is software-defined, meaning that it provides a flexible and \n",
       "programmable interface for developers to create, deploy, and manage ML/AI models. This allows for greater \n",
       "customization and control over the platform.\n",
       "\u001b[1;36m3\u001b[0m. **Tensor Processing**: Groq's platform is designed to efficiently process tensor operations, which are a \n",
       "fundamental component of many ML/AI algorithms. This enables fast and accurate processing of complex models.\n",
       "\u001b[1;36m4\u001b[0m. **Scalability**: The Groq platform is designed to scale horizontally, allowing organizations to easily add or \n",
       "remove nodes as needed to accommodate changing workloads.\n",
       "\u001b[1;36m5\u001b[0m. **Integration with Popular Frameworks**: Groq supports popular ML/AI frameworks such as TensorFlow, PyTorch, and\n",
       "Caffe, making it easy for developers to integrate the platform into their existing workflows.\n",
       "\n",
       "**Benefits:**\n",
       "The Groq platform offers several benefits, including:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Faster Processing Times**: Groq's hardware acceleration and optimized software stack enable faster processing \n",
       "times for ML/AI workloads, reducing the time it takes to train and deploy models.\n",
       "\u001b[1;36m2\u001b[0m. **Improved Efficiency**: The platform's efficient design and optimized hardware reduce power consumption and \n",
       "heat generation, making it more cost-effective and environmentally friendly.\n",
       "\u001b[1;36m3\u001b[0m. **Simplified Development**: Groq's software-defined platform and support for popular frameworks simplify the \n",
       "development and deployment of ML/AI models, reducing the complexity and expertise required.\n",
       "\u001b[1;36m4\u001b[0m. **Increased Accuracy**: The platform's optimized hardware and software enable more accurate processing of ML/AI \n",
       "models, leading to better outcomes and decision-making.\n",
       "\n",
       "**Target Use Cases:**\n",
       "The Groq platform is designed for a wide range of use cases, including:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Computer Vision**: Image and video processing, object detection, and image classification.\n",
       "\u001b[1;36m2\u001b[0m. **Natural Language Processing**: Text classification, sentiment analysis, and language translation.\n",
       "\u001b[1;36m3\u001b[0m. **Recommendation Systems**: Personalized recommendations, predictive analytics, and decision-making.\n",
       "\u001b[1;36m4\u001b[0m. **Autonomous Vehicles**: Sensor processing, object detection, and motion forecasting.\n",
       "\n",
       "Overall, the Groq platform has the potential to revolutionize the way organizations approach machine learning and \n",
       "artificial intelligence, enabling faster, more efficient, and more accurate processing of complex workloads.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(llm.invoke(\"hi explain me about Groq platform \").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691eff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d4bdfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\n",
    "    \"https://docs.langchain.com/oss/python/langchain/overview\",\n",
    "    \"https://docs.langchain.com/oss/python/langchain/agents\",\n",
    "    \"https://docs.langchain.com/oss/python/langchain/structured-output\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5e5d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[WebBaseLoader(url).load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "123570d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[doc for sublist in docs for doc in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e542351",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)\n",
    "doc_splits=text_splitter.split_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0a7841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.langchain.com/oss/python/langchain/overview'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LangChain overview - Docs by LangChain'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"LangChain overview - Docs by LangChainSkip to main contentWe've raised a $125M Series B to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">build the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">LangGraphSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">AgentsIntegrationsLearnReferenceContributePythonOverviewLangChain v1.0Release notesMigration guideGet </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">startedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">memoryStreamingMiddlewareStructured outputAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">(MCP)Human-in-the-loopMulti-agentRetrievalLong-term memoryUse in productionStudioTestDeployAgent Chat </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">UIObservabilityEnglishcloseOn this page Install Create an agent Core benefitsLangChain overviewCopy pageCopy </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">pageLangChain v1.0 is now available!For a complete list of changes and instructions on how to upgrade your code, </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">see the release notes and migration guide.If you encounter any issues or have\"</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.langchain.com/oss/python/langchain/overview'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'LangChain overview - Docs by LangChain'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'to upgrade your code, see the release notes and migration guide.If you encounter any issues </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.langchain.com/oss/python/langchain/overview'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'LangChain overview - Docs by LangChain'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m\"LangChain\u001b[0m\u001b[32m overview - Docs by LangChainSkip to main contentWe've raised a $125M Series B to \u001b[0m\n",
       "\u001b[32mbuild the platform for agent engineering. Read more.Docs by LangChain home pageLangChain + \u001b[0m\n",
       "\u001b[32mLangGraphSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangChain overviewLangChainLangGraphDeep \u001b[0m\n",
       "\u001b[32mAgentsIntegrationsLearnReferenceContributePythonOverviewLangChain v1.0Release notesMigration guideGet \u001b[0m\n",
       "\u001b[32mstartedInstallQuickstartPhilosophyCore componentsAgentsModelsMessagesToolsShort-term \u001b[0m\n",
       "\u001b[32mmemoryStreamingMiddlewareStructured outputAdvanced usageGuardrailsRuntimeContext engineeringModel Context Protocol \u001b[0m\n",
       "\u001b[32m(\u001b[0m\u001b[32mMCP\u001b[0m\u001b[32m)\u001b[0m\u001b[32mHuman-in-the-loopMulti-agentRetrievalLong-term memoryUse in productionStudioTestDeployAgent Chat \u001b[0m\n",
       "\u001b[32mUIObservabilityEnglishcloseOn this page Install Create an agent Core benefitsLangChain overviewCopy pageCopy \u001b[0m\n",
       "\u001b[32mpageLangChain v1.0 is now available!For a complete list of changes and instructions on how to upgrade your code, \u001b[0m\n",
       "\u001b[32msee the release notes and migration guide.If you encounter any issues or have\"\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.langchain.com/oss/python/langchain/overview'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'LangChain overview - Docs by LangChain'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'to upgrade your code, see the release notes and migration guide.If you encounter any issues \u001b[0m\n",
       "\u001b[32mor have feedback, please open an issue so we can improve. To view v0.x documentation, go to the archived content.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(doc_splits[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c77f5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OllamaEmbeddings(model=\"llama3:8b\")\n",
    ")\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebc57f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'a5f6ef4d-f8d8-4235-94bc-e334f35f0291'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.langchain.com/oss/python/langchain/structured-output'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Structured output - Docs by LangChain'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'If handle_errors is a tuple of exceptions, the agent will only retry (using the default error</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">message) if the exception raised is one of the specified types. In all other cases, the exception will be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">raised.\\nCustom error handler function:\\nCopyAsk AIdef custom_error_handler(error: Exception) -&gt; str:\\n    if </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">isinstance(error, StructuredOutputValidationError):\\n        return \"There was an issue with the format. Try </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">again.\\n    elif isinstance(error, MultipleStructuredOutputsError):\\n        return \"Multiple structured outputs </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">were returned. Pick the most relevant one.\"\\n    else:\\n        return f\"Error: {str(error)}\"\\n\\nToolStrategy(\\n   </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">schema=ToolStrategy(Union[ContactInfo, EventDetails]),\\n    handle_errors=custom_error_handler\\n)\\n\\nOn </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">StructuredOutputValidationError:\\nCopyAsk AI================================= Tool Message </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">=================================\\nName: ToolStrategy\\n\\nThere was an issue with the format. Try again.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'34cad85d-2550-49c7-8acb-e6c5c944d5db'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.langchain.com/oss/python/langchain/agents'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Agents - Docs by LangChain'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'agent = create_agent(\\n    model,\\n    tools=tools,\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">middleware=[CustomMiddleware()]\\n)\\n\\n# The agent can now track additional state beyond messages\\nresult = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agent.invoke({\\n    \"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"user_preferences\": {\"style\": \"technical\", \"verbosity\": \"detailed\"},\\n})\\n\\n\\u200bDefining state via </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">state_schema\\nUse the state_schema parameter as a shortcut to define custom state that is only used in </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tools.\\nCopyAsk AIfrom langchain.agents import AgentState\\n\\n\\nclass CustomState(AgentState):\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">user_preferences: dict\\n\\nagent = create_agent(\\n    model,\\n    tools=[tool1, tool2],\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">state_schema=CustomState\\n)\\n# The agent can now track additional state beyond messages\\nresult = agent.invoke({\\n </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"messages\": [{\"role\": \"user\", \"content\": \"I prefer technical explanations\"}],\\n    \"user_preferences\": {\"style\": </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"technical\", \"verbosity\": \"detailed\"},\\n})'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'1f10aed7-433f-4db4-8c03-faa67fc56f8c'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.langchain.com/oss/python/langchain/structured-output'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Structured output - Docs by LangChain'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'handling strategiesCore componentsStructured outputCopy pageCopy pageStructured output allows</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">agents to return data in a specific, predictable format. Instead of parsing natural language responses, you get </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">structured data in the form of JSON objects, Pydantic models, or dataclasses that your application can directly </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">use.'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'0b547788-fcd4-4e02-84d6-74fd279e8b7a'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.langchain.com/oss/python/langchain/structured-output'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'title'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Structured output - Docs by LangChain'</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'language'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'en'</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'If handle_errors is a string, the agent will always prompt the model to re-try with a fixed </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">tool message:\\nCopyAsk AI================================= Tool Message =================================\\nName: </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ProductRating\\n\\nPlease provide a valid rating between 1-5 and include a comment.\\n\\nHandle specific exceptions </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">only:\\nCopyAsk AIToolStrategy(\\n    schema=ProductRating,\\n    handle_errors=ValueError  # Only retry on </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">ValueError, raise others\\n)\\n\\nIf handle_errors is an exception type, the agent will only retry (using the default </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">error message) if the exception raised is the specified type. In all other cases, the exception will be </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">raised.\\nHandle multiple exception types:\\nCopyAsk AIToolStrategy(\\n    schema=ProductRating,\\n    </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">handle_errors=(ValueError, TypeError)  # Retry on ValueError and TypeError\\n)'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'a5f6ef4d-f8d8-4235-94bc-e334f35f0291'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.langchain.com/oss/python/langchain/structured-output'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Structured output - Docs by LangChain'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'If handle_errors is a tuple of exceptions, the agent will only retry \u001b[0m\u001b[32m(\u001b[0m\u001b[32musing the default error\u001b[0m\n",
       "\u001b[32mmessage\u001b[0m\u001b[32m)\u001b[0m\u001b[32m if the exception raised is one of the specified types. In all other cases, the exception will be \u001b[0m\n",
       "\u001b[32mraised.\\nCustom error handler function:\\nCopyAsk AIdef custom_error_handler\u001b[0m\u001b[32m(\u001b[0m\u001b[32merror: Exception\u001b[0m\u001b[32m)\u001b[0m\u001b[32m -> str:\\n    if \u001b[0m\n",
       "\u001b[32misinstance\u001b[0m\u001b[32m(\u001b[0m\u001b[32merror, StructuredOutputValidationError\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n        return \"There was an issue with the format. Try \u001b[0m\n",
       "\u001b[32magain.\\n    elif isinstance\u001b[0m\u001b[32m(\u001b[0m\u001b[32merror, MultipleStructuredOutputsError\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n        return \"Multiple structured outputs \u001b[0m\n",
       "\u001b[32mwere returned. Pick the most relevant one.\"\\n    else:\\n        return f\"Error: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mstr\u001b[0m\u001b[32m(\u001b[0m\u001b[32merror\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\"\\n\\nToolStrategy\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n   \u001b[0m\n",
       "\u001b[32mschema\u001b[0m\u001b[32m=\u001b[0m\u001b[32mToolStrategy\u001b[0m\u001b[32m(\u001b[0m\u001b[32mUnion\u001b[0m\u001b[32m[\u001b[0m\u001b[32mContactInfo, EventDetails\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\n    \u001b[0m\u001b[32mhandle_errors\u001b[0m\u001b[32m=\u001b[0m\u001b[32mcustom_error_handler\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nOn \u001b[0m\n",
       "\u001b[32mStructuredOutputValidationError:\\nCopyAsk \u001b[0m\u001b[32mAI\u001b[0m\u001b[32m================================= Tool Message \u001b[0m\n",
       "\u001b[32m=================================\\nName: ToolStrategy\\n\\nThere was an issue with the format. Try again.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'34cad85d-2550-49c7-8acb-e6c5c944d5db'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.langchain.com/oss/python/langchain/agents'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Agents - Docs by LangChain'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'agent = create_agent\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n    model,\\n    \u001b[0m\u001b[32mtools\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtools\u001b[0m\u001b[32m,\\n    \u001b[0m\n",
       "\u001b[32mmiddleware\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32mCustomMiddleware\u001b[0m\u001b[32m(\u001b[0m\u001b[32m)\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n# The agent can now track additional state beyond messages\\nresult = \u001b[0m\n",
       "\u001b[32magent.invoke\u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n    \"messages\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"role\": \"user\", \"content\": \"I prefer technical explanations\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\\n    \u001b[0m\n",
       "\u001b[32m\"user_preferences\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"style\": \"technical\", \"verbosity\": \"detailed\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\n\\u200bDefining state via \u001b[0m\n",
       "\u001b[32mstate_schema\\nUse the state_schema parameter as a shortcut to define custom state that is only used in \u001b[0m\n",
       "\u001b[32mtools.\\nCopyAsk AIfrom langchain.agents import AgentState\\n\\n\\nclass CustomState\u001b[0m\u001b[32m(\u001b[0m\u001b[32mAgentState\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n    \u001b[0m\n",
       "\u001b[32muser_preferences: dict\\n\\nagent = create_agent\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n    model,\\n    \u001b[0m\u001b[32mtools\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32mtool1, tool2\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\\n    \u001b[0m\n",
       "\u001b[32mstate_schema\u001b[0m\u001b[32m=\u001b[0m\u001b[32mCustomState\u001b[0m\u001b[32m\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n# The agent can now track additional state beyond messages\\nresult = agent.invoke\u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n \u001b[0m\n",
       "\u001b[32m\"messages\": \u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"role\": \"user\", \"content\": \"I prefer technical explanations\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m,\\n    \"user_preferences\": \u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"style\": \u001b[0m\n",
       "\u001b[32m\"technical\", \"verbosity\": \"detailed\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m,\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'1f10aed7-433f-4db4-8c03-faa67fc56f8c'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.langchain.com/oss/python/langchain/structured-output'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Structured output - Docs by LangChain'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'handling strategiesCore componentsStructured outputCopy pageCopy pageStructured output allows\u001b[0m\n",
       "\u001b[32magents to return data in a specific, predictable format. Instead of parsing natural language responses, you get \u001b[0m\n",
       "\u001b[32mstructured data in the form of JSON objects, Pydantic models, or dataclasses that your application can directly \u001b[0m\n",
       "\u001b[32muse.'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m,\n",
       "    \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m\n",
       "        \u001b[33mid\u001b[0m=\u001b[32m'0b547788-fcd4-4e02-84d6-74fd279e8b7a'\u001b[0m,\n",
       "        \u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "            \u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.langchain.com/oss/python/langchain/structured-output'\u001b[0m,\n",
       "            \u001b[32m'title'\u001b[0m: \u001b[32m'Structured output - Docs by LangChain'\u001b[0m,\n",
       "            \u001b[32m'language'\u001b[0m: \u001b[32m'en'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[33mpage_content\u001b[0m=\u001b[32m'If handle_errors is a string, the agent will always prompt the model to re-try with a fixed \u001b[0m\n",
       "\u001b[32mtool message:\\nCopyAsk \u001b[0m\u001b[32mAI\u001b[0m\u001b[32m================================= Tool Message =================================\\nName: \u001b[0m\n",
       "\u001b[32mProductRating\\n\\nPlease provide a valid rating between 1-5 and include a comment.\\n\\nHandle specific exceptions \u001b[0m\n",
       "\u001b[32monly:\\nCopyAsk AIToolStrategy\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n    \u001b[0m\u001b[32mschema\u001b[0m\u001b[32m=\u001b[0m\u001b[32mProductRating\u001b[0m\u001b[32m,\\n    \u001b[0m\u001b[32mhandle_errors\u001b[0m\u001b[32m=\u001b[0m\u001b[32mValueError\u001b[0m\u001b[32m  # Only retry on \u001b[0m\n",
       "\u001b[32mValueError, raise others\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\nIf handle_errors is an exception type, the agent will only retry \u001b[0m\u001b[32m(\u001b[0m\u001b[32musing the default \u001b[0m\n",
       "\u001b[32merror message\u001b[0m\u001b[32m)\u001b[0m\u001b[32m if the exception raised is the specified type. In all other cases, the exception will be \u001b[0m\n",
       "\u001b[32mraised.\\nHandle multiple exception types:\\nCopyAsk AIToolStrategy\u001b[0m\u001b[32m(\u001b[0m\u001b[32m\\n    \u001b[0m\u001b[32mschema\u001b[0m\u001b[32m=\u001b[0m\u001b[32mProductRating\u001b[0m\u001b[32m,\\n    \u001b[0m\n",
       "\u001b[32mhandle_errors\u001b[0m\u001b[32m=\u001b[0m\u001b[32m(\u001b[0m\u001b[32mValueError, TypeError\u001b[0m\u001b[32m)\u001b[0m\u001b[32m  # Retry on ValueError and TypeError\\n\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n",
       "    \u001b[1m)\u001b[0m\n",
       "\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(retriever.invoke(\"what is Structured output ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427f3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3413ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool=create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_vector_db_blog\",\n",
    "    \"search and run information about langchain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "885c3c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Tool</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'retriever_vector_db_blog'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">description</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'search and run information about langchain.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">args_schema</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'langchain_core.tools.retriever.RetrieverInput'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">func</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">functools</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.partial</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;function _get_relevant_documents at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x000002995916F240</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">retriever</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VectorStoreRetriever</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">tags</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'FAISS'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'OllamaEmbeddings'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">vectorstore</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;langchain_community.vectorstores.faiss.FAISS object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x00000299579303B0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;, </span><span style=\"color: #808000; text-decoration-color: #808000\">search_kwargs</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{})</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">document_prompt</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'page_content'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">input_types</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">template</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'{page_content}'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">document_separator</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'\\n\\n'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #808000; text-decoration-color: #808000\">response_format</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008000; text-decoration-color: #008000\">'content'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">)</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">    </span><span style=\"color: #808000; text-decoration-color: #808000\">coroutine</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">functools</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.partial</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #000000; text-decoration-color: #000000\">&lt;function _aget_relevant_documents at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x0000029957C42660</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">retriever</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">VectorStoreRetriever</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">tags</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'FAISS'</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span><span style=\"color: #008000; text-decoration-color: #008000\">'OllamaEmbeddings'</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">]</span><span style=\"color: #000000; text-decoration-color: #000000\">, </span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">vectorstore</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;langchain_community.vectorstores.faiss.FAISS object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x00000299579303B0</span><span style=\"font-weight: bold\">&gt;</span>, <span style=\"color: #808000; text-decoration-color: #808000\">search_kwargs</span>=<span style=\"font-weight: bold\">{})</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">document_prompt</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PromptTemplate</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">input_variables</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'page_content'</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">input_types</span>=<span style=\"font-weight: bold\">{}</span>, <span style=\"color: #808000; text-decoration-color: #808000\">partial_variables</span>=<span style=\"font-weight: bold\">{}</span>, \n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">template</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{page_content}'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">document_separator</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'\\n\\n'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">response_format</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'content'</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mTool\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mname\u001b[0m=\u001b[32m'retriever_vector_db_blog'\u001b[0m,\n",
       "    \u001b[33mdescription\u001b[0m=\u001b[32m'search and run information about langchain.'\u001b[0m,\n",
       "    \u001b[33margs_schema\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'langchain_core.tools.retriever.RetrieverInput'\u001b[0m\u001b[39m>,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mfunc\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mfunctools\u001b[0m\u001b[1;35m.partial\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39m<function _get_relevant_documents at \u001b[0m\u001b[1;36m0x000002995916F240\u001b[0m\u001b[39m>, \u001b[0m\n",
       "\u001b[33mretriever\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mVectorStoreRetriever\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mtags\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'FAISS'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'OllamaEmbeddings'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[33mvectorstore\u001b[0m\u001b[39m=<langchain_community.vectorstores.faiss.FAISS object at \u001b[0m\u001b[1;36m0x00000299579303B0\u001b[0m\u001b[39m>, \u001b[0m\u001b[33msearch_kwargs\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[33mdocument_prompt\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mPromptTemplate\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33minput_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'page_content'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m\u001b[33minput_types\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m, \u001b[0m\u001b[33mpartial_variables\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[33mtemplate\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mpage_content\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m, \u001b[0m\u001b[33mdocument_separator\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'\\n\\n'\u001b[0m\u001b[39m, \u001b[0m\u001b[33mresponse_format\u001b[0m\u001b[39m=\u001b[0m\u001b[32m'content'\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[39m    \u001b[0m\u001b[33mcoroutine\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mfunctools\u001b[0m\u001b[1;35m.partial\u001b[0m\u001b[1;39m(\u001b[0m\u001b[39m<function _aget_relevant_documents at \u001b[0m\u001b[1;36m0x0000029957C42660\u001b[0m\u001b[39m>, \u001b[0m\n",
       "\u001b[33mretriever\u001b[0m\u001b[39m=\u001b[0m\u001b[1;35mVectorStoreRetriever\u001b[0m\u001b[1;39m(\u001b[0m\u001b[33mtags\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m[\u001b[0m\u001b[32m'FAISS'\u001b[0m\u001b[39m, \u001b[0m\u001b[32m'OllamaEmbeddings'\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m, \u001b[0m\n",
       "\u001b[33mvectorstore\u001b[0m\u001b[39m=<langchain_community.vectorstores.faiss.FAISS object at \u001b[0m\u001b[1;36m0x00000299579303B0\u001b[0m\u001b[1m>\u001b[0m, \u001b[33msearch_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\u001b[1m)\u001b[0m, \n",
       "\u001b[33mdocument_prompt\u001b[0m=\u001b[1;35mPromptTemplate\u001b[0m\u001b[1m(\u001b[0m\u001b[33minput_variables\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'page_content'\u001b[0m\u001b[1m]\u001b[0m, \u001b[33minput_types\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[33mpartial_variables\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \n",
       "\u001b[33mtemplate\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mpage_content\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m, \u001b[33mdocument_separator\u001b[0m=\u001b[32m'\\n\\n'\u001b[0m, \u001b[33mresponse_format\u001b[0m=\u001b[32m'content'\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(retriever_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd8f5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## another vector database for langgraph \n",
    "\n",
    "urls=[\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/overview\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/thinking-in-langgraph\",\n",
    "    \"https://docs.langchain.com/oss/python/langgraph/workflows-agents\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25e272e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[WebBaseLoader(doc).load() for doc in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb13b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list=[items for sublist in docs for items in sublist ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e571a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f06d3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_splits=text_splitter.split_documents(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98614523",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=OllamaEmbeddings(model=\"llama3:8b\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5173c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67059ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_tool2=create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retriever_vector_db_blog2\",\n",
    "    \"search and run information about langraph.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1b75b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[retriever_tool,retriever_tool2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1e26830",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Graph work flow \n",
    "\n",
    "from langgraph.graph import StateGraph,END,START\n",
    "from typing_extensions import TypedDict \n",
    "from typing import Annotated,Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c2c506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm=ChatOllama(model=\"llama3:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59418b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Ollama!\n",
       "\n",
       "Ollama is a popular online game that has gained significant popularity, especially among gamers and puzzle \n",
       "enthusiasts. It's a simple yet addictive game where players try to match falling blocks <span style=\"font-weight: bold\">(</span>called <span style=\"color: #008000; text-decoration-color: #008000\">\"ollas\"</span><span style=\"font-weight: bold\">)</span> in order \n",
       "to remove them from the game board.\n",
       "\n",
       "Here's how it works:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The game starts with an empty grid.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Ollas of different shapes and colors start falling from above, one by one.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. Players can rotate each olla to try to fit it into a horizontal or vertical line with already fallen ollas.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. If the player successfully fits an olla into a line, all the ollas in that line disappear, and any connected \n",
       "lines above them will collapse.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. The goal is to clear as many lines as possible without letting the ollas pile up too high.\n",
       "\n",
       "The game requires strategic thinking, quick reflexes, and a bit of luck. As players progress, the pace of falling \n",
       "ollas increases, making it more challenging to make matches.\n",
       "\n",
       "Ollama has become a viral sensation, with millions of players worldwide trying to beat their scores and compete \n",
       "with others online.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Ollama!\n",
       "\n",
       "Ollama is a popular online game that has gained significant popularity, especially among gamers and puzzle \n",
       "enthusiasts. It's a simple yet addictive game where players try to match falling blocks \u001b[1m(\u001b[0mcalled \u001b[32m\"ollas\"\u001b[0m\u001b[1m)\u001b[0m in order \n",
       "to remove them from the game board.\n",
       "\n",
       "Here's how it works:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. The game starts with an empty grid.\n",
       "\u001b[1;36m2\u001b[0m. Ollas of different shapes and colors start falling from above, one by one.\n",
       "\u001b[1;36m3\u001b[0m. Players can rotate each olla to try to fit it into a horizontal or vertical line with already fallen ollas.\n",
       "\u001b[1;36m4\u001b[0m. If the player successfully fits an olla into a line, all the ollas in that line disappear, and any connected \n",
       "lines above them will collapse.\n",
       "\u001b[1;36m5\u001b[0m. The goal is to clear as many lines as possible without letting the ollas pile up too high.\n",
       "\n",
       "The game requires strategic thinking, quick reflexes, and a bit of luck. As players progress, the pace of falling \n",
       "ollas increases, making it more challenging to make matches.\n",
       "\n",
       "Ollama has become a viral sensation, with millions of players worldwide trying to beat their scores and compete \n",
       "with others online.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(llm.invoke(\"what is ollama\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a572b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state):\n",
    "    \"\"\" \n",
    "    Invokes the agent model to generate a response based on the current state . Given the question,  it\n",
    "    will decide to retrieve using retriever tool or simply end.\n",
    "\n",
    "    Args : \n",
    "        state(messages) : the current state\n",
    "\n",
    "    returns: \n",
    "        dict : the updated state with the agent response appended to messages\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"-- Call Agent -- \")\n",
    "    messages=state[\"messages\"]\n",
    "    model=llm.bind_tools(tools)\n",
    "    response=model.invoke(messages)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ee80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
